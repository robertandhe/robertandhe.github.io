---
layout: post
title: "推荐系统-DeepFM算法理论详解"
subtitle: ''
date:     2020-02-15 16:34:00
author: "mudux"
music: false
music-id: 187937
mathjax: true
# header-img: "img/post-bg-2015.jpg"
header-style: text
catalog: true
tags:
  - machine learning
  - recommender system
---

## 1. 介绍
&emsp;在CTR预估中，特征交互(feature interactions)对模型的性能有很大影响。在DeepFM模型出现之前，现有模型通常偏向低阶或者高阶交叉，或者需要特征工程。[DeepFM paper](https://www.ijcai.org/Proceedings/2017/0239.pdf)提出了一个端到端的同时考虑低阶和高阶特征交互的模型DeepFM。这个模型结合了FM模型学习二阶交叉和DNN模型特征学习的优点。并和FNN,PNN,Wide&Deep模型做了对比。实验结果显示了DeepFM模型的effectiveness和efficiency。

## 2. DeepFM模型
### 2.1 数据集
&emsp;设数据集为$$D=\left\{(x^{(1)}, y^{(1)}),(x^{(1)}, y^{(1)}),\cdots, (x^{(m)}, y^{(m)})\right\}$$。其中$x$是一个m-fields数据。$y\in{0,1}$表示标签，1为用户点击，0为不点击。$x$可能包括类别fields(如gender,location)和连续fields(如age)，每一个类别field表示为一个one-hot编码向量，连续field用它本身表示或者离散化后的one-hot向量表示。所以$x=\left[x_{field_1},x_{field_2},\cdots,x_{field_j},\cdots, x_{field_m}\right]$是一个$d$维向量，其中$x_{field_j}$是第$j$个field的向量表示。
### 2.2 DeepFM
&emsp;所以想同时学习低阶和高阶特征交互，提出了DeepFM模型，模型结构如下图所示：
![DeepFM arch](https://gitee.com/alston972/MarkDownPhotos/raw/master/2020-02-15/DeepFMarch.PNG)  
&emsp;DeepFM模型由FM component和deep component两部分组成，这两部分共享输入。  
&emsp;对特征$i$，标量$w_i$用来表示1阶重要性，隐向量$\rm V_i$表示它和其他特征的交互作用。把$\rm V_i$输入FM component获取二阶特征交互，输入deep component获取高阶特征交互。
所有参数包括$w_i$,$\rm V_i$和网络参数($W^{(l)},b^{(l)}$)按照下述模型进行联合训练：

$$\widehat y=sigmoid(y_{FM}+y_{DNN})$$

&emsp;其中$\widehat y\in(0,1)$是预测的CTR,$y_{FM}$是FM component的输出，$y_{DNN}$是deep component的输出。

### 2.3 FM component
![FM component](https://gitee.com/alston972/MarkDownPhotos/raw/master/2020-02-15/FMComp.PNG)  
&emsp;如上图所示，FM component的输出是**Addition**单元和**Inner Product**单元的和。

$$y_{FM}=\left<w,x\right>+\sum\limits_{i=1}^{d}\sum\limits_{j=i+1}^{d}\left<V_i,V_j\right>x_i\cdot x_j$$

&emsp;其中$w\in R^{d},V_i\in R^k$,$k$是隐向量维度。Addition单元($\left<w,x\right>$)表示特征一阶重要性，Inner Product单元反映特征二阶交互。

### 2.4 Deep Component
![Deep component](https://gitee.com/alston972/MarkDownPhotos/raw/master/2020-02-15/DeepComp.PNG)  
&emsp;deep component就是一个前向神经网络，用来学习高阶特征交互。但CTR数据集通常是高度稀疏的，所以在送入隐含层前需要一个embedding layer把输入向量压缩到低维稠密实值向量，否则可能过拟合。
![embedding](https://gitee.com/alston972/MarkDownPhotos/raw/master/2020-02-15/embedding.PNG)  
&emsp;上图显示了embedding层的结构。这里有两点需要注意：
- 尽管不同输入field向量的长度不一样，但embedding长度都是k;
- FM中隐向量V就相当于网络权重，用来把输入field向量压缩到embedding向量。

&emsp;设embedding层的输出向量为：

$$a^{(0)}=\left[e_1,e_2,\cdots, e_m\right]$$

&emsp;其中$e_i$是第i个field的embedding，$m$是field数量。然后把$a^{(0)}$输入DNN,

$$a^{l+1}=\sigma \left(W^{(l)}a^{(l)}+b^{(l)}\right)$$
最终输出为

$$y_{DNN}=W^{|H|+1}\cdot a^{|H|}+b^{|H|+1}$$

&emsp;其中，$$|H|$$
是隐含层数量。

&emsp;注意在DeepFM模型中FM component和deep component共享相同的特征embedding,这有两个优点：
- 从raw feature中学习低阶和高阶特征交互；
- 无需做特征工程。

### 2.5 与其它NN关系
![comparasion](https://gitee.com/alston972/MarkDownPhotos/raw/master/2020-02-15/comparasion.PNG)
**FNN**  
&emsp;FNN(见上图左)是一个用FM初始化的DNN。FNN的预训练有两个缺点：
- embedding参数很受FM影响；
- 预训练影响efficiency。
- FNN仅考虑高阶特征交互。

&emsp;相比之下，DeepFM不需要预训练并且同时学习低阶和高阶特征交互。

**PNN**  
&emsp;为了学习高阶特征交互，PNN(见上图中)在embedding层和第一个隐层之间添加了一个product层。按照乘积操作的不同，基于內积的IPNN，基于外积的OPNN，基于內积和外积的PNN*。和FNN一样，PNN也仅考虑高阶特征交互。

**Wide & Deep**  
&emsp;Wide & Deep(见上图右)同时学习低阶和高阶特征交互。如图所示，wide部分输入需要特征工程。相比之下，DeepFM不需要做特征工程，直接从raw feature学习(可以用FM替换LR部分，但DeepFM的FM部分和deep部分共享特征embedding)。

&emsp;几个模型对比如下表所示：
![compTab](https://gitee.com/alston972/MarkDownPhotos/raw/master/2020-02-15/compTab.PNG)  
&emsp;总的来说，**DeepFM不需要预训练，不需要做特征工程，同时学习低阶和高阶特征交互**。

## 3. Reference
[1. DeepFM-paper](https://www.ijcai.org/Proceedings/2017/0239.pdf)  
[2. DeepFM算法解析及Python实现](https://www.cnblogs.com/wkang/p/9881921.html)  
[3. DeepFM-tensorflow code-github](https://github.com/ChenglongChen/tensorflow-DeepFM)  